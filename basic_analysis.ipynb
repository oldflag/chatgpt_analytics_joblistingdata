{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "# Load the dataset from the ZIP file\n",
    "zip_path = './archive.zip'  # Adjust this path as necessary\n",
    "extracted_folder_path = './extracted_data'\n",
    "\n",
    "# Extract the ZIP file\n",
    "with ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_folder_path)\n",
    "\n",
    "# Assuming there is only one CSV file in the ZIP, or you know the file name\n",
    "csv_file_name = 'gsearch_jobs.csv'  # Adjust this filename as necessary\n",
    "csv_file_path = os.path.join(extracted_folder_path, csv_file_name)\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Identify non-numeric columns and rename \"via\" column to \"job platform\"\n",
    "data.rename(columns={'via': 'job platform'}, inplace=True)\n",
    "\n",
    "# Remove \"via \" prefix from the \"job platform\" column values\n",
    "data['job platform'] = data['job platform'].str.replace('via ', '')\n",
    "\n",
    "# Clean non-numeric columns by removing leading and trailing spaces\n",
    "non_numeric_columns = data.select_dtypes(exclude=['int64', 'float64']).columns\n",
    "data[non_numeric_columns] = data[non_numeric_columns].apply(lambda x: x.astype(str).str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plotting histograms for numeric columns\n",
    "numeric_columns = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "def plot_numeric_columns(df, columns):\n",
    "    n_cols = 3\n",
    "    n_rows = (len(columns) + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*6, n_rows*4))\n",
    "    fig.tight_layout(pad=5.0)\n",
    "    \n",
    "    for i, column in enumerate(columns):\n",
    "        ax = axes[i//n_cols, i%n_cols]\n",
    "        sns.histplot(df[column], bins=30, ax=ax, kde=True if df[column].nunique() > 1 else False)\n",
    "        ax.set_title(column)\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('Frequency')\n",
    "\n",
    "    # Hide any unused axes\n",
    "    for j in range(i + 1, n_cols * n_rows):\n",
    "        axes[j//n_cols, j%n_cols].set_visible(False)\n",
    "\n",
    "plot_numeric_columns(data, numeric_columns)\n",
    "\n",
    "def plot_non_numeric_columns(df, columns, n_top=10):\n",
    "    n_cols = 2\n",
    "    n_rows = (len(columns) + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*10, n_rows*5))\n",
    "    fig.tight_layout(pad=6.0)\n",
    "\n",
    "    for i, column in enumerate(columns):\n",
    "        ax = axes[i//n_cols, i%n_cols]\n",
    "        top_categories = df[column].value_counts().head(n_top)\n",
    "        sns.barplot(x=top_categories, y=top_categories.index, ax=ax)\n",
    "        ax.set_title(f'Top {n_top} {column}')\n",
    "        ax.set_xlabel('Frequency')\n",
    "        ax.set_ylabel('')\n",
    "\n",
    "    # Hide any unused axes\n",
    "    for j in range(i + 1, n_cols * n_rows):\n",
    "        axes[j//n_cols, j%n_cols].set_visible(False)\n",
    "\n",
    "# Select a subset of non-numeric columns to visualize due to high cardinality in some columns\n",
    "columns_to_visualize = ['title','company_name', 'location', 'job platform', 'schedule_type', 'work_from_home']\n",
    "\n",
    "# Plotting bar charts for selected non-numeric columns\n",
    "plot_non_numeric_columns(data, columns_to_visualize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset to include only rows with non-null yearly salary data\n",
    "salary_data = data[data['salary_yearly'].notnull()]\n",
    "\n",
    "# Group by 'job platform', calculate the average yearly salary, and count the job listings\n",
    "platform_salary = salary_data.groupby('job platform')['salary_yearly'].agg(['mean', 'count'])\n",
    "\n",
    "# Sort the job platforms by the count of job listings and then select the top 10\n",
    "top_platforms = platform_salary.sort_values(by='count', ascending=False).head(10)\n",
    "\n",
    "# Sort the top platforms by the average yearly salary for plotting\n",
    "top_platforms_sorted_by_salary = top_platforms.sort_values(by='mean', ascending=True)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=top_platforms_sorted_by_salary['mean'], y=top_platforms_sorted_by_salary.index)\n",
    "plt.title('Top 10 Job Platforms by Average Yearly Salary')\n",
    "plt.xlabel('Average Yearly Salary ($)')\n",
    "plt.ylabel('Job Platform')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Next, plot the top 10 most common job title based on yearly average salary\n",
    "# Filter the dataset to include only rows with non-null yearly salary data\n",
    "salary_data = data[data['salary_yearly'].notnull()]\n",
    "\n",
    "# Group by 'title', calculate the average yearly salary, and count the job listings\n",
    "title_salary = salary_data.groupby('title')['salary_yearly'].agg(['mean', 'count'])\n",
    "\n",
    "# Sort the job titles by the average yearly salary and then select the top 10\n",
    "top_titles = title_salary.sort_values(by='mean', ascending=False).head(10)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=top_titles['mean'], y=top_titles.index, palette=\"Blues_d\")\n",
    "plt.title('Top 10 titles by Average Yearly Salary')\n",
    "plt.xlabel('Average Yearly Salary ($)')\n",
    "plt.ylabel('title')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Next, plot the top 10 most common title frequently include yearly salary and what the average salaries are for those titles\n",
    "# Filter the dataset to include only rows with non-null yearly salary data\n",
    "salary_data = data[data['salary_yearly'].notnull()]\n",
    "\n",
    "# Group by 'title', calculate the average yearly salary, and count the job listings\n",
    "title_salary = salary_data.groupby('title')['salary_yearly'].agg(['mean', 'count'])\n",
    "\n",
    "# Sort the job titles by the count of job listings and then select the top 10\n",
    "top_titles = title_salary.sort_values(by='count', ascending=False).head(10)\n",
    "\n",
    "# Sort the top titles by the average yearly salary for plotting\n",
    "top_titles_sorted_by_salary = top_titles.sort_values(by='mean', ascending=True)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x=top_titles_sorted_by_salary['mean'], y=top_titles_sorted_by_salary.index)\n",
    "plt.title('Top 10 Job Titles by Average Yearly Salary')\n",
    "plt.xlabel('Average Yearly Salary ($)')\n",
    "plt.ylabel('Job Title')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where 'salary_yearly' is NaN\n",
    "data_clean = data.dropna(subset=['salary_yearly'])\n",
    "\n",
    "# Proceed with preprocessing\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "X = data_clean[['title', 'job platform', 'location']]\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "y = data_clean['salary_yearly']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest Regressor\n",
    "random_forest_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "\n",
    "# Feature importance\n",
    "feature_names = encoder.get_feature_names_out(input_features=['title', 'job platform', 'location'])\n",
    "importances = random_forest_model.feature_importances_\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the top 10 most important features\n",
    "print(\"Top 10 Feature Importances:\")\n",
    "for i in range(10):\n",
    "    print(f\"{feature_names[sorted_indices[i]]}: {importances[sorted_indices[i]]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Ensuring that the salary_yearly column doesn't have NaN values\n",
    "data = data.dropna(subset=['salary_yearly'])\n",
    "\n",
    "# Preparing the features matrix X by one-hot encoding the categorical variables\n",
    "# Preparing the target vector y\n",
    "encoder = OneHotEncoder()\n",
    "X = encoder.fit_transform(data[['title', 'job platform', 'location']])\n",
    "y = data['salary_yearly']\n",
    "\n",
    "# Splitting the dataset into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initializing the Random Forest Regressor\n",
    "random_forest = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the yearly salary on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculating the Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the yearly salary on new data  \n",
    "chatGPT Prompt:  \n",
    "Let's predict the yearly salary of new data using the model  \n",
    "here is a new data:  \n",
    "title: Data Analyst  \n",
    "platform: LinkedIn  \n",
    "location: United States  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "# For predicting the salary of the new data, we first need to one-hot encode it using the same encoder used during training\n",
    "# Create a DataFrame with the new data\n",
    "new_data = pd.DataFrame([{'title': 'Data Analyst', 'job platform': 'LinkedIn', 'location': 'United States'}])\n",
    "\n",
    "# One-hot encode the new data\n",
    "new_data_encoded = encoder.transform(new_data)\n",
    "\n",
    "# Predict the yearly salary using the trained model\n",
    "predicted_salary = random_forest.predict(new_data_encoded)\n",
    "predicted_salary[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
